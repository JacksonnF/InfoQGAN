{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hid_size) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hid_size, out_size) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, out_size),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_points = 2000 # From paper\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "x = np.random.uniform(low=0.25, high=0.75, size=N_points)\n",
    "y = np.random.uniform(low=0.25, high=0.75, size=N_points)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(x, y, alpha=1, s=10)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(\"Central Square Distribution (2000 points)\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')  # Make the plot square\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class XYDistribution(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.stack((self.x[idx], self.y[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 4\n",
    "\n",
    "net_D = Discriminator(2, 4)\n",
    "net_G = Generator(noise_size, 4, 2)\n",
    "\n",
    "batch_size = 40\n",
    "\n",
    "dataset = XYDistribution(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = 0.5 + torch.randn(batch_size, noise_size)*2\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "epochs = 1000\n",
    "lr = 1e-4\n",
    "\n",
    "optimizerD = optim.Adam(net_D.parameters(), lr=lr)\n",
    "optimizerG = optim.Adam(net_G.parameters(), lr=lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_error = []\n",
    "g_error = []\n",
    "fk_prog = []\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        # First Update Discriminator with batch of Real Data\n",
    "        net_D.zero_grad()\n",
    "        labels_real = torch.ones((batch_size, 1))\n",
    "        outputs = net_D(batch)\n",
    "        loss_d_real = criterion(outputs, labels_real)\n",
    "        loss_d_real.backward()\n",
    "\n",
    "        # Update with \"Fake\" Generator Data\n",
    "        rand_inps = 0.5 + torch.randn((batch_size, noise_size)) * 2\n",
    "        gen_outp = net_G(rand_inps)\n",
    "        labels_fk = torch.zeros((batch_size, 1))\n",
    "        outputs = net_D(gen_outp)\n",
    "        loss_d_fake = criterion(outputs, labels_fk)\n",
    "        loss_d_fake.backward()\n",
    "\n",
    "        loss_d = loss_d_fake + loss_d_real\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update the Generator Network to Maximize Discriminator Error\n",
    "        net_G.zero_grad()\n",
    "        # Do D forward pass again on newly updated network\n",
    "        labels_real_gen = torch.ones((batch_size, 1))\n",
    "        gen_outp_2 = net_G(rand_inps)\n",
    "        outputs = net_D(gen_outp_2)\n",
    "        loss_g = criterion(outputs, labels_real_gen)\n",
    "        loss_g.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        d_error.append(loss_d.item())\n",
    "        g_error.append(loss_g.item())\n",
    "    print(\"Discriminator Loss: \", loss_d.item(), \"Generator Loss\", loss_g.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake = net_G(fixed_noise)\n",
    "        # print(\"GENERATOR PROGRESS: \", fake)\n",
    "        fk_prog.append(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_output = net_G(0.5+torch.randn((50000, noise_size))*2)\n",
    "\n",
    "x_test = gen_output[:, 0].detach().numpy()\n",
    "y_test = gen_output[:, 1].detach().numpy()\n",
    "\n",
    "\n",
    "# Plot test data\n",
    "def plot_xy(x_pts, y_pts):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(x_test, y_test, alpha=1, s=10)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(\"Test Generator Output\")\n",
    "    plt.gca().set_aspect('equal', adjustable='box')  # Make the plot square\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_xy(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpen400qproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
